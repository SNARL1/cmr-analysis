---
title: "70550 - Create datasets for analysis using *mrmr*"
author: "Roland Knapp"
output: html_notebook
editor_options: 
  chunk_output_type: inline
---

This notebook creates the survey, capture, and translocation files for use in analyzing capture-mark-recapture data using the *mrmr* package. The code retrieves data from the PostgreSQL amphibians database, runs error checks, and creates the relevant files in *mrmr* format. 

Users without credentials to access the database will not be able to create or use the raw data file that is central to this notebook. See cmr-analysis/README.md for details. 

Note that data from the most recent field season may not yet be appended to tables in the amphibians database. If these recently-collected data are necessary (e.g., for preliminary analyses), complete datasets can be created by copying code chunks in "fulcrum_data_append.Rmd" into this notebook and executing all code chunks. 

## Load packages
```{r load_packages}
library(tidyverse)
library(RPostgreSQL)
library(lubridate)
library(assertthat)
library(assertr)
options(readr.show_col_types = FALSE)
```

## Create translocation dataset
Not all sites have received frog translocations. Run or skip the following code chunks as necessary. 

### Connect to PostgreSQL database. 
```{r}
con = dbConnect(dbDriver("PostgreSQL"),
                host = Sys.getenv("host"), 
                port = Sys.getenv("port"), 
                dbname = Sys.getenv("dbname"),
                user = rstudioapi::askForPassword("user name"),
                password = rstudioapi::askForPassword("password")
               )
```

### Retrieve translocation data from database
```{sql retrieve_translocation_data, connection=con, output.var = "translocation_70550"}
select 
  release_siteid1, 
  release_date, 
  type, 
  pit_tag_ref, 
  tag_new,
  sex,
  length,
  weight,
  swab_id,
  relocate.comment as comment_relocate,
  relocate_frog.comment as comment_relocate_frog,
  relocate.id as relocate_id,
  relocate_frog.id as relocate_frog_id
from relocate
inner join relocate_frog on relocate.id = relocate_id
where release_siteid1 = 70550 and
      type = 'translocation'
```
```{r}
dbDisconnect(con)
rm(con)
```
Review the translocation data subset for potential problems. 

### Save/retrieve raw translocation data
```{r save_raw_translocation_data, message=FALSE}
translocation_70550 %>% write_csv(here::here("data", "raw", "70550_translocation_raw.csv"))
```
```{r read_raw_translocation_data, message=FALSE}
translocation_70550 <- read_csv(here::here("data", "raw", "70550_translocation_raw.csv")) %>% 
  mutate(pit_tag_ref = as.character(pit_tag_ref))
```

### Translocation data checks
Run checks before and after data cleaning (next code chunk) to ensure that all issues have been resolved. Run lines of code one at a time to allow easy evaluation of messages and outputs. 
```{r translocation_data_checks, message=FALSE}
# Check for records where pit_tag_ref is NULL
assert_that(noNA(translocation_70550$pit_tag_ref))

# Check for records containing pit tags shorter than 15 characters (or 9 for early sites)
assert_that(!any(nchar(translocation_70550$pit_tag_ref) != 15))

# Check for records containing pit tags that end with ".1" (known to be potentially incorrect) 
assert_that(!any(str_detect(translocation_70550$pit_tag_ref, "\\.1$")))

# Check for records of subadult frogs
translocation_70550 %>% drop_na(length) %>% filter(length < 40)

# Check for frogs that died during translocation
translocation_70550 %>% filter(grepl("dead", comment_relocate_frog) | grepl("died", comment_relocate_frog))

# Check for duplicate pit tags on each date
translocation_70550 %>% count(release_date, pit_tag_ref) %>% filter(n > 1)

# Are release dates correct?
translocation_70550 %>% distinct(release_date) %>% glimpse()
```

### Clean translocation data
```{r clean_translocation_data}
# No problems to clean
```

### Create final translocation dataset formatted for mrmr
```{r final_translocation_data}
translocation_70550_mrmr <- translocation_70550 %>% 
  rename(pit_tag_id = pit_tag_ref,
         site_id = release_siteid1) %>% 
  arrange(release_date, pit_tag_id) %>% 
  select(site_id, type, release_date, pit_tag_id)
```

### Save/retrieve cleaned translocation data
```{r save_cleaned_translocation_data, message=FALSE}
translocation_70550_mrmr %>% write_csv(here::here("data", "clean", "70550_translocation.csv"))
```
```{r read_cleaned_translocation_data, message=FALSE}
translocation_70550 <- read_csv(here::here("data", "clean", "70550_translocation.csv")) %>% 
  mutate(pit_tag_id = as.character(pit_tag_id))
```

## Create survey dataset

### Connect to PostgreSQL database. 
```{r}
con = dbConnect(dbDriver("PostgreSQL"),
                host = Sys.getenv("host"), 
                port = Sys.getenv("port"), 
                dbname = Sys.getenv("dbname"),
                user = rstudioapi::askForPassword("user name"),
                password = rstudioapi::askForPassword("password")
               )
```

### Retrieve survey data from database
If surveys at which no frogs were captured are classified as "ves", include in "where" statement (e.g., where site_id = 70619 and survey_type in ('cmr', 'visual'))
```{sql retrieve_survey_data, connection=con, output.var = "survey_70550"}
select 
  site_id, 
  visit_date, 
  visit_status, 
  survey_type, 
  description, 
  survey_quality,
  wind,
  sky,
  duration,
  visit.comment as comment_visit,
  survey.comment as comment_survey
from visit
inner join survey on visit.id = visit_id
where site_id = 70550 and
      survey_type = 'cmr'
```
```{r, message=FALSE}
dbDisconnect(con)
rm(con)
```

### Save/retrieve raw survey data
```{r save_raw_survey_data, message=FALSE}
survey_70550 %>% write_csv(here::here("data", "raw", "70550_survey_raw.csv"))
```
```{r read_raw_survey_data, message=FALSE}
survey_70550 <- read_csv(here::here("data", "raw", "70550_survey_raw.csv"))
```

### When multiple numbered sites exist in survey area, include only one survey for entire site on each survey date
70550 is the primary site at this location and was surveyed during each secondary period. 
Because cmr and visual surveys exist for same date, keep cmr survey only. Change survey_type "visual" to "cmr".
Restrict date range to include only relevant surveys.
```{r check_survey_history}
# Check if primary site was surveyed during each visit
survey_70550 %>% 
  add_count(visit_date) %>% 
  filter(n == 1 & site_id != "70550")
```
```{r include_relevant_surveys}
# When only cmr surveys exist in survey history
survey_70550 <- survey_70550 %>% 
  filter(site_id == 70550) %>%
  rename(survey_date = visit_date)
```

### Add translocation dates as surveys
To meet mrmr format requirement
```{r add_translocation_surveys}
survey_70550_mrmr <- translocation_70550_mrmr %>% 
  distinct(site_id, release_date, type) %>% 
  rename(survey_type = type, survey_date = release_date) %>% bind_rows(survey_70550) %>% 
  arrange(survey_date) 
```
Review records for potential problematic surveys, for example, based on comment fields and fields describing current conditions.

### Survey data checks
Run checks before and after data cleaning (next code chunk) to ensure that all issues have been resolved.
```{r survey_data_checks}
# Check for duplicate survey dates
survey_70550_mrmr %>% count(site_id, survey_date) %>% filter(n > 1)

# Check for sites that were unsuitable for survey
survey_70550_mrmr %>% filter(visit_status != "suitable")
```

### Clean survey data
```{r clean_survey_data}
# Drop incomplete surveys and duplicate surveys
survey_70550_mrmr<- survey_70550_mrmr %>% 
  filter(survey_date != "2007-05-31" & survey_date != "2018-08-14") %>% 
  distinct(survey_date, .keep_all = TRUE)
```

### Create primary and secondary period columns in mrmr format
```{r create_period_columns}
# For combine robust design and single-visit dataset
survey_70550_mrmr <- survey_70550_mrmr %>% 
  select(site_id, survey_date, survey_type) %>% 
  filter(survey_date < "2013-07-29") %>% 
  mutate(primary_period = row_number()) %>% 
  right_join(survey_70550_mrmr, by = c("site_id", "survey_date", "survey_type")) %>% 
  mutate(primary_period = replace(primary_period, between(survey_date, ymd("2013-07-29"), ymd("2013-07-31")), 32),
         primary_period = replace(primary_period, between(survey_date, ymd("2013-08-03"), ymd("2013-08-04")), 33),
         primary_period = replace(primary_period, survey_date == "2013-08-08", 34), 
         primary_period = replace(primary_period, survey_date == "2013-08-14", 35),
         primary_period = replace(primary_period, between(survey_date, ymd("2013-08-18"), ymd("2013-08-20")), 36),
         primary_period = replace(primary_period, between(survey_date, ymd("2013-08-26"), ymd("2013-08-28")), 37),
         primary_period = replace(primary_period, between(survey_date, ymd("2013-09-09"), ymd("2013-09-11")), 38),
         primary_period = replace(primary_period, survey_date == "2014-06-24", 39),
         primary_period = replace(primary_period, between(survey_date, ymd("2014-07-14"), ymd("2014-07-16")), 40),
         primary_period = replace(primary_period, between(survey_date, ymd("2014-08-10"), ymd("2014-08-12")), 41),
         primary_period = replace(primary_period, between(survey_date, ymd("2014-09-07"), ymd("2014-09-09")), 42),
         primary_period = replace(primary_period, between(survey_date, ymd("2015-07-10"), ymd("2015-07-12")), 43),
         primary_period = replace(primary_period, between(survey_date, ymd("2015-08-04"), ymd("2015-08-06")), 44),
         primary_period = replace(primary_period, between(survey_date, ymd("2015-09-02"), ymd("2015-09-04")), 45),
         primary_period = replace(primary_period, between(survey_date, ymd("2016-07-12"), ymd("2016-07-14")), 46),
         primary_period = replace(primary_period, between(survey_date, ymd("2016-08-10"), ymd("2016-08-12")), 47),
         primary_period = replace(primary_period, between(survey_date, ymd("2017-08-10"), ymd("2017-08-12")), 48),
         primary_period = replace(primary_period, between(survey_date, ymd("2018-06-28"), ymd("2018-06-30")), 49),
         primary_period = replace(primary_period, between(survey_date, ymd("2018-08-16"), ymd("2018-08-18")), 50),
         primary_period = replace(primary_period, between(survey_date, ymd("2019-07-31"), ymd("2019-08-02")), 51),
         primary_period = replace(primary_period, between(survey_date, ymd("2020-07-01"), ymd("2020-07-03")), 52),
         primary_period = replace(primary_period, between(survey_date, ymd("2020-08-27"), ymd("2020-08-29")), 53),
         primary_period = replace(primary_period, between(survey_date, ymd("2021-06-23"), ymd("2021-06-25")), 54),
         primary_period = replace(primary_period, between(survey_date, ymd("2021-08-16"), ymd("2021-08-18")), 55)) %>% 
  arrange(primary_period, survey_date) %>% 
  group_by(primary_period) %>% 
  mutate(secondary_period = seq_len(n()),
         secondary_period = replace(secondary_period, survey_type == "translocation", 0)) 
  
survey_70550_mrmr <- survey_70550_mrmr %>% 
  select(site_id, survey_date, survey_type, primary_period, secondary_period)
```

### Save/retrieve cleaned survey file
```{r save_cleaned_survey_data}
survey_70550_mrmr %>% write_csv(here::here("data", "clean", "70550_survey.csv"))
```
```{r read_cleaned_survey_data}
survey_70550 <- read_csv(here::here("data", "clean", "70550_survey.csv"))
```

## Create capture dataset

### Connect to PostgreSQL database. 
```{r}
con = dbConnect(dbDriver("PostgreSQL"),
                host = Sys.getenv("host"), 
                port = Sys.getenv("port"), 
                dbname = Sys.getenv("dbname"),
                user = rstudioapi::askForPassword("user name"),
                password = rstudioapi::askForPassword("password")
               )
```

### Retrieve frog capture data from database
```{sql retrieve_capture_data, connection=con, output.var = "capture_70550"}
select 
  site_id, 
  visit_date, 
  visit_status, 
  survey_type, 
  pit_tag_ref, 
  tag_new, 
  species, 
  capture_life_stage, 
  capture_animal_state, 
  length, 
  visit.comment as comment_visit,
  survey.comment as comment_survey,
  capture_survey.comment as comment_capture,
  visit.id as visit_id,
  survey.id as survey_id,
  capture_survey.id as capture_id
from visit
inner join survey on visit.id = visit_id
inner join capture_survey on survey.id = survey_id
where site_id = 70550 and
      survey_type = 'cmr'
```
```{r, message=FALSE}
dbDisconnect(con)
rm(con)
```

### Save/retrieve raw capture data
```{r save_raw_capture_data, message=FALSE}
capture_70550 %>% write_csv(here::here("data", "raw", "70550_capture_raw.csv"))
```
```{r read_raw_capture_data, message=FALSE}
capture_70550 <- read_csv(here::here("data", "raw", "70550_capture_raw.csv")) %>% 
  mutate(pit_tag_ref = as.character(pit_tag_ref))
```
Review records for potential problematic captures, for example, based on comment fields and fields describing frog characteristics (including tag_new).

### Retain only relevant columns
```{r capture_relevant_columns}
capture_70550 <- capture_70550 %>% 
  select(-visit_id, -survey_id, -capture_id)
```

### Capture data checks
Run checks before and after data cleaning)
```{r capture_data_checks, message=FALSE}
# Check for records where pit_tag_ref is NULL
assert_that(noNA(capture_70550$pit_tag_ref))

# Check for records containing pit tags shorter than 15 characters (or 9 for early sites)
assert_that(!any(nchar(capture_70550$pit_tag_ref) != 15))

# Check for records containing pit tags that end with ".1" (known to be potentially incorrect) 
assert_that(!any(str_detect(capture_70550$pit_tag_ref, "\\.1$")))

# Check for records where species != ramu
capture_70550 %>% drop_na(species) %>% filter(species != "ramu")

# Check for records were survey_type = swab
assert_that(!any(capture_70550$survey_type == "swab"))

# Check for records where capture_animal_state is NULL
assert_that(noNA(capture_70550$capture_animal_state))

# Check for records where capture_animal_state == "dead"
assert_that(!any(capture_70550$capture_animal_state == "dead"))

# Check for records of subadult frogs
capture_70550 %>% drop_na(length) %>% filter(length < 40)

# Check for sites that were unsuitable for survey
assert_that(!any(capture_70550$visit_status != "suitable"))

# Check for duplicate capture records on each date
capture_70550 %>% count(visit_date, pit_tag_ref) %>% filter(n > 1)

# Check for captures that lack associated surveys
survey_70550_mrmr %>% 
  select(survey_date, primary_period) %>% 
  rename(visit_date = survey_date) %>% 
  right_join(capture_70550, by = c("visit_date")) %>% 
  filter(is.na(primary_period))

# Check for surveys that lack associated captures
survey_70550_mrmr %>% 
  select(survey_date, primary_period) %>% 
  rename(visit_date = survey_date) %>% 
  left_join(capture_70550, by = c("visit_date")) %>% 
  filter(is.na(species))
```

### Clean capture data
```{r clean_capture_data}
# Drop records where pit_tag_ref is NULL
capture_70550 <- capture_70550 %>% 
  filter(!is.na(pit_tag_ref))

# Remove pit_tag_ref ".1" suffix
capture_70550 <- capture_70550 %>% 
  mutate(pit_tag_ref = replace(pit_tag_ref, pit_tag_ref == "982000365440256.1", "982000365440256"))

# Drop dead frogs
capture_70550 <- capture_70550 %>% 
  filter(capture_animal_state != "dead")

# Drop captures from excluded surveys
capture_70550 <- capture_70550 %>% 
  filter(visit_date != "2007-05-31" & visit_date != "2018-08-14")

# Check for subadult frogs indicated one 39 mm SVL frog in dataset - did not remove
```

### Create final capture dataset formatted for mrmr
```{r final_capture_data}
capture_70550_mrmr <- capture_70550 %>%
  rename(survey_date = visit_date, pit_tag_id = pit_tag_ref) %>%
  arrange(survey_date, pit_tag_id) %>%
  select(site_id, survey_date, pit_tag_id)
```

### Save/retrieve cleaned capture data
```{r save_cleaned_capture_data}
capture_70550_mrmr %>% write_csv(here::here("data", "clean", "70550_capture.csv"))
```
```{r read_cleaned_capture_data}
capture_70550 <- read_csv(here::here("data", "clean", "70550_capture.csv"))
```







