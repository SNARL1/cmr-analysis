---
title: "10114 - Create datasets for analysis using *mrmr*"
author: "Roland Knapp"
output: html_notebook
editor_options: 
  chunk_output_type: inline
---
## CMR data creation - Goddard 10114

This notebook creates the survey, capture, and translocation files for use in analyzing capture-mark-recapture data using the *mrmr* package. The code retrieves data from the PostgreSQL amphibians database, runs error checks, and creates the relevant files in *mrmr* format. The code is written in distinct chunks to allow review of results from one chunk before running the next. For example, review of the raw data files is necessary to identify potentially problematic records for review and possible removal from the data set.

Before using the code in this file, replace all instances of "xxxxx" with the 5-digit site_id of interest. 

Users without credentials to access the database can use the saved CSV files created in the save-raw-data-files code chunk.

Note for credentialed users: Data from the most recent field season may not yet be appended to tables in the amphibians database.
If these recently-collected data are necessary (e.g., for preliminary analyses), complete datasets can be created by copying code chunks in "fulcrum_data_append.Rmd" into this notebook and executing all code chunks.

## Load packages

```{r load-packages}
library(tidyverse)
library(RPostgreSQL)
library(lubridate)
library(assertthat)
# options(readr.show_col_types = FALSE)
```
## Retrieve data from PostgreSQL database

### Connect to database

- When connecting via SSH, open external connection to database, then replace "Sys.getenv" with "rstudioapi::askForPassword" for host and port, run chunk.   
- Users without credentials can use CSV files created in code chunk "save-raw-data-files" below as a starting point.  

```{r db-connect}
con = dbConnect(dbDriver("PostgreSQL"),
                host = Sys.getenv("host"), 
                port = Sys.getenv("port"), 
                dbname = Sys.getenv("dbname"),
                user = rstudioapi::askForPassword("user name"),
                password = rstudioapi::askForPassword("password")
               )
# dbListTables(con)
```

### Retrieve translocation/reintroduction data from database

- Skip if translocations and/or reintroductions are not relevant.  
- Edit "where" statement to include relevant site_ids and types.  

```{sql retrieve_translocation_data, connection=con, output.var = "translocation_10114"}
select 
  release_siteid1, 
  release_date, 
  type, 
  pit_tag_ref, 
  tag_new,
  sex,
  length,
  weight,
  swab_id,
  relocate.comment as comment_relocate,
  relocate_frog.comment as comment_relocate_frog,
  relocate.id as relocate_id,
  relocate_frog.id as relocate_frog_id
from relocate
inner join relocate_frog on relocate.id = relocate_id
where release_siteid1 in (10114, 11886, 11889) and
      type = 'reintroduction'  
```

### Retrieve survey data from database

- Edit "where" statement to include relevant site_ids and types.
- If some relevant surveys are classified as "ves", include in "where" statement. 

```{sql retrieve-survey-data, connection=con, output.var = "survey_10114"}
select 
  site_id, 
  visit_date, 
  visit_status, 
  survey_type, 
  description, 
  survey_quality,
  wind,
  sky,
  air_temp,
  duration,
  visit.comment as comment_visit,
  survey.comment as comment_survey
from visit
inner join survey on visit.id = visit_id
where site_id in (10114, 11886, 11889) and
      survey_type = 'cmr'
```

### Retrieve frog capture data from database

- Edit "where" statement to include relevant site_ids and types. 

```{sql retrieve-capture-data, connection=con, output.var = "capture_10114"}
select 
  site_id, 
  visit_date, 
  visit_status, 
  survey_type, 
  pit_tag_ref, 
  tag_new, 
  species, 
  capture_life_stage, 
  capture_animal_state, 
  length, 
  visit.comment as comment_visit,
  survey.comment as comment_survey,
  capture_survey.comment as comment_capture,
  visit.id as visit_id,
  survey.id as survey_id,
  capture_survey.id as capture_id
from visit
inner join survey on visit.id = visit_id
inner join capture_survey on survey.id = survey_id
where site_id in (10114, 11886, 11889) and
      survey_type = 'cmr'
```

```{r db-disconnect3}
dbDisconnect(con)
rm(con)
```

- Review retrieved datasets before using in subsequent chunks.  

### Save raw data files
```{r save-raw-data-files, message=FALSE}
translocation_10114 %>% write_csv(here::here("data", "raw", "10114_translocation_raw.csv")) # if relevant
survey_10114 %>% write_csv(here::here("data", "raw", "10114_survey_raw.csv"))
capture_10114 %>% write_csv(here::here("data", "raw", "10114_capture_raw.csv"))
```

- Read saved files with (for example): translocation_10114 <- read_csv(here::here("data", "raw", "10114_translocation_raw.csv")) %>% 
  mutate(pit_tag_ref = as.character(pit_tag_ref))

## Create translocation/reintroduction dataset

- Skip if translocations/reintroductions are not relevant.  

### Retain only relevant columns

```{r translocation-relevant-columns}
translocation_10114 <- translocation_10114 %>% 
  rename(site_id = release_siteid1) %>% 
  select(site_id, release_date, type, pit_tag_ref, tag_new, sex, length, weight, swab_id)
```

### Translocation data checks

- Run checks before and after data cleaning (next code chunk) to ensure that all issues have been resolved.  
- Run lines of code one at a time to allow easy evaluation of messages and outputs.  

```{r translocation-data-checks, message=FALSE}
# Check for records where pit_tag_ref is NULL
assert_that(noNA(translocation_10114$pit_tag_ref))

# Check for records containing pit tags shorter than 15 characters
assert_that(!any(nchar(translocation_10114$pit_tag_ref) != 15))

# Check for records containing pit tags that end with ".1" (known to be potentially incorrect) 
assert_that(!any(str_detect(translocation_10114$pit_tag_ref, "\\.1$")))

# Check for records of subadult frogs
translocation_10114 %>% drop_na(length) %>% filter(length < 40)
### in 10114 in 2023, one 39 mm frog was released, but it was PIT tagged at the Zoo.

# Check for duplicate pit tags on each date
translocation_10114 %>% count(release_date, pit_tag_ref) %>% filter(n > 1)

# Are release dates correct?
translocation_10114 %>% distinct(release_date) %>% glimpse()
```

### Clean translocation data

- Edit data-cleaning code as necessary.  

```{r clean-translocation-data}
translocation_10114 <- translocation_10114 %>% 
  filter(!is.na(pit_tag_ref))
```

### Create final translocation dataset formatted for mrmr

```{r final-translocation-data}
translocation_10114 <- translocation_10114 %>% 
  rename(pit_tag_id = pit_tag_ref) %>% 
  arrange(release_date, pit_tag_id) %>% 
  select(site_id, type, release_date, pit_tag_id)
```

### Save cleaned translocation data

```{r save-cleaned-translocation-data, message=FALSE}
# name file with reintroduction which is more accurate for this site.
translocation_10114 %>% write_csv(here::here("data", "clean", "10114_reintroduction.csv"))
```

- When reading dataset, format pit_tag_id as character.  

## Create survey dataset

### Include only relevant surveys

- When multiple numbered sites exist in survey area, include only one survey for entire site on each survey date. 

#### Primary site surveyed during each secondary period?

- If yes, code chunk will return zero records. Exclude other records as necessary. 
- In filter statement, edit site_id as necessary.

```{r check-survey-history}
survey_10114 %>% 
  add_count(visit_date) %>% 
  filter(n == 1 & site_id != "10114")
```

#### Include only surveys at primary site

- Run this code chunk as is when only CMR surveys need to be included. If VES surveys also need to be included, modify code accordingly. 

```{r include-relevant-surveys}
survey_10114 <- survey_10114 %>% 
  filter(site_id == 10114) %>%
  rename(survey_date = visit_date) %>% 
  arrange(survey_date)
```

### Add translocation/reintroduction dates as surveys

- Skip if translocations/reintroductions are not relevant.  

```{r add-translocation-surveys}
survey_10114 <- translocation_10114 %>% 
  distinct(site_id, release_date, type) %>% 
  rename(survey_type = type, survey_date = release_date) %>% bind_rows(survey_10114) %>% 
  arrange(survey_date) 
```

### Survey data checks

- Run checks before and after data cleaning (next code chunk) to ensure that all issues have been resolved.  
- Run lines of code one at a time to allow easy evaluation of messages and outputs.  

```{r survey-data-checks}
# Check for duplicate survey dates
survey_10114 %>% count(site_id, survey_date) %>% filter(n > 1)

# Check for sites that were unsuitable for survey
survey_10114 %>% filter(visit_status != "suitable")
```

### Clean survey data

- Edit data-cleaning code as necessary. 

```{r clean-survey-data}
# Drop duplicate surveys
survey_10114 <- survey_10114 %>% 
  distinct(survey_date, .keep_all = TRUE) %>% 
  arrange(site_id, survey_date)
```

### Create primary and secondary period columns in mrmr format

- Edit case_when steps to reflect actual translocation/reintroduction and survey history.  

#### For robust design dataset

This will ultimately be reflected in the relocate data, but the first Goddard reintroductions occurred on 2021-07-28.

```{r create-period-columns1}
# make reintro dates single day primary periods
survey_10114 <- survey_10114 %>%
  select(site_id, survey_date, survey_type) %>% 
  mutate(primary_period = case_when(# survey_date == "2021-07-28" ~ 1, # this is the date of the first Goddard reintro, although not currently appearing in the relocate data table.
                                    between(survey_date, ymd("2022-07-18"), ymd("2022-07-20")) ~ 1,
                                    survey_date == "2022-07-21" ~ 2,
                                    between(survey_date, ymd("2023-08-25"), ymd("2023-08-27")) ~ 3,
                                    survey_date == "2023-08-28" ~ 4 #,
                                    # 2024 survey
                                    # 2024 reintro
                                    # 2024 survey
                                    ) 
        )
                                    
survey_10114 <- survey_10114 %>% 
  arrange(primary_period, survey_date) %>% 
  group_by(primary_period) %>% 
  mutate(secondary_period = seq_len(n()),
         secondary_period = replace(secondary_period, survey_type != "cmr", 0)) 
```
### Save cleaned survey file

```{r save-cleaned-survey-data}
survey_10114 %>% write_csv(here::here("data", "clean", "10114_survey.csv"))
```

## Create capture dataset

### Retain only relevant columns

```{r capture-relevant-columns}
capture_10114 <- capture_10114 %>% 
  select(-visit_id, -survey_id, -capture_id)
```

### Capture data checks

- Run checks before and after data cleaning (next code chunk) to ensure that all issues have been resolved.  
- Run lines of code one at a time to allow easy evaluation of messages and outputs.  

```{r capture-data-checks, message=FALSE}
# Check for records where pit_tag_ref is NULL
assert_that(noNA(capture_10114$pit_tag_ref))

# Check for records containing pit tags shorter than 15 characters (or 9 for early sites)
assert_that(!any(nchar(capture_10114$pit_tag_ref) != 15))

# Check for records containing pit tags that end with ".1" (known to be potentially incorrect) 
assert_that(!any(str_detect(capture_10114$pit_tag_ref, "\\.1$")))

# Check for records where species != ramu
capture_10114 %>% drop_na(species) %>% filter(species != "ramu")

# Check for records were survey_type = swab
assert_that(!any(capture_10114$survey_type == "swab"))

# Check for records where capture_animal_state is NULL
assert_that(noNA(capture_10114$capture_animal_state))

# Check for records where capture_animal_state == "dead"
assert_that(!any(capture_10114$capture_animal_state == "dead"))

# Check for records of subadult frogs
capture_10114 %>% drop_na(length) %>% filter(length < 40)

# Check for sites that were unsuitable for survey
assert_that(!any(capture_10114$visit_status != "suitable"))

# Check for duplicate capture records on each date
capture_10114 %>% count(visit_date, pit_tag_ref) %>% filter(n > 1)

# Check for captures that lack associated surveys
survey_10114 %>% 
  select(survey_date, primary_period) %>% 
  rename(visit_date = survey_date) %>% 
  right_join(capture_10114, by = c("visit_date")) %>% 
  filter(is.na(primary_period))

# Simpler alternative
setdiff(capture_10114$visit_date, survey_10114$survey_date) %>% as.Date(origin = "1970-01-01")

# Check for surveys that lack associated captures
survey_10114 %>% 
  filter(survey_type == "cmr") %>% 
  select(survey_date, primary_period) %>% 
  rename(visit_date = survey_date) %>% 
  left_join(capture_10114, by = c("visit_date")) %>% 
  filter(is.na(species))
# at goddard 10114, the first resurvey day in 2022 found no frogs.

# Simpler alternative
setdiff(survey_10114$survey_date, capture_10114$visit_date) %>% as.Date(origin = "1970-01-01")
# this suggests that at Goddard 10114, three survey says turned up no frogs - but, two of those dates are reintro dates and not true surveys.
```

### Clean capture data

- Edit data-cleaning code as necessary.  

```{r clean-capture-data}
capture_10114 <- capture_10114 %>% 
  filter(capture_animal_state != "dead")
```

### Create final capture dataset formatted for mrmr

```{r final-capture-data}
capture_10114 <- capture_10114 %>%
  rename(survey_date = visit_date, pit_tag_id = pit_tag_ref) %>%
  arrange(survey_date, pit_tag_id) %>%
  select(site_id, survey_date, pit_tag_id)
```

### Save cleaned capture data

```{r save-cleaned-capture-data}
capture_10114 %>% write_csv(here::here("data", "clean", "10114_capture.csv"))
```
